{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w7hNhEtFK42s"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructField,\n",
    "    StructType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    ")\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.sql.functions import when, count, col, isnan, isnull, mean, stddev\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    StringIndexer,\n",
    "    ChiSqSelector,\n",
    ")\n",
    "from pyspark.ml import regression\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression, LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PRuXeu1iK9Gh"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"LogisticRegressionModel\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-uNMUVOK7a_",
    "outputId": "3d7e6469-dce4-43c6-c086-6cfe91be7a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "|default|housing|loan|deposit|customerID|job_admin|job_blue-collar|job_entrepreneur|job_housemaid|job_management|job_retired|job_self-employed|job_services|job_student|job_technician|job_unemployed|marital_divorced|marital_married|marital_single|education_primary|education_secondary|education_tertiary|education_unknown|contact_cellular|contact_telephone|contact_unknown|month_apr|month_aug|month_dec|month_feb|month_jan|month_jul|month_jun|month_mar|month_may|month_nov|month_oct|month_sep|poutcome_failure|poutcome_other|poutcome_success|poutcome_unknown|                 age|             balance|                day|          duration|           campaign|              pdays|          previous|\n",
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "|      0|      1|   0|      1|         0|        1|              0|               0|            0|             0|          0|                0|           0|          0|             0|             0|               0|              1|             0|                0|                  1|                 0|                0|               0|                0|              1|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|        0|               0|             0|               0|               1|    1.49550243220936| 0.25341386093328744|-1.2667138320258027|1.9275199876040967|-0.5539521829097113|-0.4814368433202895|-0.362947229569182|\n",
      "|      0|      0|   0|      1|         1|        1|              0|               0|            0|             0|          0|                0|           0|          0|             0|             0|               0|              1|             0|                0|                  1|                 0|                0|               0|                0|              1|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|        0|               0|             0|               0|               1|  1.2435017489186544| -0.4592900114108695|-1.2667138320258027|3.1506688258160103|-0.5539521829097113|-0.4814368433202895|-0.362947229569182|\n",
      "|      0|      1|   0|      1|         2|        0|              0|               0|            0|             0|          0|                0|           0|          0|             1|             0|               0|              1|             0|                0|                  1|                 0|                0|               0|                0|              1|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|        0|               0|             0|               0|               1|-0.01650166753487...|-0.07936736405595554|-1.2667138320258027|2.9261850390382946|-0.5539521829097113|-0.4814368433202895|-0.362947229569182|\n",
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+--------------------+-------------------+------------------+-------------------+-------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read csv file using spark\n",
    "df = spark.read.csv(\"newdata.csv\", header=True, inferSchema=True)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bf-yOpPhSsjW"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z1vl0eX4RVIt"
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"deposit\", outputCol=\"label\")\n",
    "df_indexed = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-GrfifBHRmgx"
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"default\", \"housing\", \"loan\", \"customerID\", \"job_admin\", \"job_blue-collar\",\n",
    "                   \"job_entrepreneur\", \"job_housemaid\", \"job_management\", \"job_retired\",\n",
    "                   \"job_self-employed\", \"job_services\", \"job_student\", \"job_technician\",\n",
    "                   \"job_unemployed\", \"marital_divorced\", \"marital_married\", \"marital_single\",\n",
    "                   \"education_primary\", \"education_secondary\", \"education_tertiary\",\n",
    "                   \"education_unknown\", \"contact_cellular\", \"contact_telephone\",\n",
    "                   \"contact_unknown\", \"month_apr\", \"month_aug\", \"month_dec\",\n",
    "                   \"month_feb\", \"month_jan\", \"month_jul\", \"month_jun\", \"month_mar\",\n",
    "                   \"month_may\", \"month_nov\", \"month_oct\", \"month_sep\",\n",
    "                   \"poutcome_failure\", \"poutcome_other\", \"poutcome_success\",\n",
    "                   \"poutcome_unknown\", \"age\", \"balance\", \"day\", \"duration\",\n",
    "                   \"campaign\", \"pdays\", \"previous\"]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_features = assembler.transform(df_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rcpPuiATRrOo"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = df_features.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cNay0JwJRtb9"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gZrw14Jki0u"
   },
   "source": [
    "**How to save and load model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "56tAM2ch6W_v"
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o194.save.\n: java.io.IOException: Path lr_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\r\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\r\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\ml\\util.py:262\u001b[0m, in \u001b[0;36mMLWritable.save\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\ml\\util.py:213\u001b[0m, in \u001b[0;36mJavaMLWriter.save\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o194.save.\n: java.io.IOException: Path lr_model already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\r\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\r\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n"
     ]
    }
   ],
   "source": [
    "lr_model.save(\"lr_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "V8fk0P83prOK"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_ALREADY_EXISTS] Path file:/c:/Users/hieud/Documents/BIGDATA/project/lr_model/train_data.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the DataFrames\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_model/train_data.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test_data\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_model/test_data.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1721\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[0;32m   1720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[1;32m-> 1721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\hieud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_ALREADY_EXISTS] Path file:/c:/Users/hieud/Documents/BIGDATA/project/lr_model/train_data.parquet already exists. Set mode as \"overwrite\" to overwrite the existing path."
     ]
    }
   ],
   "source": [
    "# Save the DataFrames\n",
    "train_data.write.parquet(\"lr_model/train_data.parquet\")\n",
    "test_data.write.parquet(\"lr_model/test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaOusYZapHnl",
    "outputId": "02c74d46-645d-478c-9a81-b0cd59a8b400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 8833\n",
      "Test Dataset Count: 2189\n",
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+------------------+-----+--------------------+\n",
      "|default|housing|loan|deposit|customerID|job_admin|job_blue-collar|job_entrepreneur|job_housemaid|job_management|job_retired|job_self-employed|job_services|job_student|job_technician|job_unemployed|marital_divorced|marital_married|marital_single|education_primary|education_secondary|education_tertiary|education_unknown|contact_cellular|contact_telephone|contact_unknown|month_apr|month_aug|month_dec|month_feb|month_jan|month_jul|month_jun|month_mar|month_may|month_nov|month_oct|month_sep|poutcome_failure|poutcome_other|poutcome_success|poutcome_unknown|                 age|            balance|                day|            duration|           campaign|              pdays|          previous|label|            features|\n",
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+------------------+-----+--------------------+\n",
      "|      0|      0|   0|      0|      5293|        0|              0|               1|            0|             0|          0|                0|           0|          0|             0|             0|               0|              1|             0|                0|                  0|                 1|                0|               1|                0|              0|        0|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|               0|             0|               0|               1|-0.01650166753487...|-0.2707243219481857|0.15932355092111095| -0.8986733279820188| -0.186285978216406|-0.4814368433202895|-0.362947229569182|  0.0|(48,[3,6,16,20,22...|\n",
      "|      0|      0|   0|      0|      5298|        0|              0|               0|            0|             0|          0|                0|           0|          0|             0|             1|               0|              1|             0|                0|                  1|                 0|                0|               1|                0|              0|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|        0|               0|             0|               0|               1| -0.8565039451705585|-0.4112181662353498|-1.1478773834468932|-0.16478402505487064| -0.186285978216406|-0.4814368433202895|-0.362947229569182|  0.0|(48,[3,14,16,19,2...|\n",
      "|      0|      0|   0|      0|      5363|        0|              0|               0|            0|             0|          0|                0|           0|          0|             1|             0|               0|              0|             1|                0|                  1|                 0|                0|               1|                0|              0|        0|        1|        0|        0|        0|        0|        0|        0|        0|        0|        0|        0|               0|             0|               0|               1|  0.9075008378643804| -0.473246353558601|-1.2667138320258027| -0.8267233963224945|0.18138022647689922|-0.4814368433202895|-0.362947229569182|  0.0|(48,[3,13,17,19,2...|\n",
      "|      0|      0|   0|      0|      5377|        0|              0|               0|            0|             0|          0|                0|           0|          0|             0|             1|               0|              1|             0|                0|                  1|                 0|                0|               1|                0|              0|        0|        0|        0|        0|        0|        0|        0|        0|        1|        0|        0|        0|               0|             0|               0|               1|  1.0755012933915173| -0.410287743425501| 0.6346693452367488| -0.8698933553182091|-0.5539521829097113|-0.4814368433202895|-0.362947229569182|  0.0|(48,[3,14,16,19,2...|\n",
      "|      0|      0|   0|      0|      5381|        0|              0|               0|            0|             0|          0|                1|           0|          0|             0|             0|               0|              1|             0|                0|                  0|                 1|                0|               1|                0|              0|        0|        1|        0|        0|        0|        0|        0|        0|        0|        0|        0|        0|               0|             0|               0|               1|    1.49550243220936|-0.4726260716853685|  1.228851588131296| -0.5993616122783976| -0.186285978216406|-0.4814368433202895|-0.362947229569182|  0.0|(48,[3,10,16,20,2...|\n",
      "+-------+-------+----+-------+----------+---------+---------------+----------------+-------------+--------------+-----------+-----------------+------------+-----------+--------------+--------------+----------------+---------------+--------------+-----------------+-------------------+------------------+-----------------+----------------+-----------------+---------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------------+--------------+----------------+----------------+--------------------+-------------------+-------------------+--------------------+-------------------+-------------------+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataset Count: \" + str(train_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kQgrgI-gkVxf"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = LogisticRegressionModel.load(\"lr_model\")\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "predictions = loaded_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oBniygElNXp",
    "outputId": "e97b525a-a238-48e7-f82a-c2236a42a038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(48,[3,6,16,20,22...|  0.0|       1.0|\n",
      "|(48,[3,14,16,19,2...|  0.0|       0.0|\n",
      "|(48,[3,13,17,19,2...|  0.0|       0.0|\n",
      "|(48,[3,14,16,19,2...|  0.0|       0.0|\n",
      "|(48,[3,10,16,20,2...|  0.0|       0.0|\n",
      "|(48,[3,13,16,19,2...|  0.0|       0.0|\n",
      "|(48,[3,14,16,18,2...|  0.0|       0.0|\n",
      "|(48,[3,10,17,20,2...|  0.0|       0.0|\n",
      "|(48,[3,7,16,20,23...|  0.0|       0.0|\n",
      "|(48,[3,10,16,19,2...|  0.0|       0.0|\n",
      "|(48,[3,11,16,21,2...|  0.0|       0.0|\n",
      "|(48,[3,4,16,19,24...|  0.0|       0.0|\n",
      "|(48,[3,8,17,20,22...|  0.0|       0.0|\n",
      "|(48,[3,8,16,19,22...|  0.0|       0.0|\n",
      "|(48,[3,13,16,20,2...|  0.0|       0.0|\n",
      "|(48,[3,5,16,19,22...|  0.0|       0.0|\n",
      "|(48,[3,11,16,18,2...|  0.0|       0.0|\n",
      "|(48,[3,4,17,19,22...|  0.0|       0.0|\n",
      "|(48,[3,8,17,20,22...|  0.0|       0.0|\n",
      "|(48,[3,9,16,19,23...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.transform(test_data)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J93Tp91DR2L5",
    "outputId": "ecbafd87-9e8a-4855-9b91-fa44197500ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9968021927820923\n",
      "Precision: 0.9968117629085269\n",
      "Recall: 0.9968021927820923\n",
      "F1-Score: 0.9968017574621731\n",
      "Root Mean Squared Error: 0.9999857623288803\n",
      "Error Rate: 0.0031978072179077205\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "# Calculate evaluation metrics\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "mse = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\", metricName=\"areaUnderROC\").evaluate(predictions)\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Calculate error rate\n",
    "total_instances = predictions.count()\n",
    "incorrect_instances = predictions.filter(predictions.label != predictions.prediction).count()\n",
    "error_rate = incorrect_instances / total_instances\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1_score}\")\n",
    "print(f\"Root Mean Squared Error: {mse ** 0.5}\")\n",
    "print(f\"Error Rate: {error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cOh3ewOcmq_3",
    "outputId": "76effe2c-bf01-415b-8682-b345f45c003b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hieud\\\\Documents\\\\BIGDATA\\\\project\\\\lr_model.zip'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "folder_to_zip = 'lr_model'\n",
    "output_filename = 'lr_model.zip'\n",
    "\n",
    "# Create a zip file\n",
    "shutil.make_archive(output_filename.replace('.zip', ''), 'zip', folder_to_zip)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
